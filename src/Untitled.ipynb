{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.data_loader import load_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockArgs:\n",
    "    def __init__(self):\n",
    "        self.bert_data_path = None\n",
    "        self.text_src = None\n",
    "        self.text_tgt = None \n",
    "        self.max_pos = 512\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = MockArgs()\n",
    "args.bert_data_path = \"../input_raw_text/\"\n",
    "args.text_src = \"../input_raw_text/amzn.txt\"\n",
    "args.text_tgt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def next_n_lines(file_opened, N):\n",
    "    return [x.strip() for x in islice(file_opened, N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coronavirus outbreak has led to a shortage of protective masks and other medical supplies, leading some sellers to significantly increase prices. Amazon has been trying to prevent the practice on its platform, alerting sellers who may be in violation of its pricing policies, according to Wired . Most states in the US have \"price gouging\" laws which prevent businesses from taking of advantage of consumers by charging exorbitant amounts of money during emergencies. Authorities in countries such as  China and Italy have also received complaints about price gouging since the outbreak, while Amazon has faced similar challenges before . Visit Business Insider's homepage for more stories .\n",
      "\n",
      "\n",
      "\n",
      "As people across the world try to protect themselves from the Wuhan coronavirus, which has now claimed 2,700 lives and infected another 80,000 , demand for medical supplies has spiked. As a result, prices for products like surgical masks have jumped to several times what they normally cost, with businesses and individuals selling masks in bulk at a premium on sites ranging from Facebook to Craigslist .\n",
      "\n",
      "\n",
      "\n",
      "However, Amazon has been cracking down on potential price-gouging on its platform, according to Wired . The report said third-party sellers have received emails from Amazon alerting them about masks that are \"not in compliance\" with the company's fair pricing policy , which bans sellers from charging \"significantly higher than recent prices offered on or off Amazon.\"\n",
      "\n",
      "\n",
      "\n",
      "Wired also reported that some listings advertising overpriced masks have been deleted from Amazon, while noting the issue of price-gouging has been fiercely debated on the Amazon seller forums .\n",
      "\n",
      "\n",
      "\n",
      "A majority of the states in the US have laws against raising prices excessively during emergencies such as natural disasters, in order to prevent businesses from taking advantage of people in need of basics like food, gas, and shelter. However, some experts argue such laws can backfire at times by encouraging people to hoard supplies.\n",
      "\n",
      "\n",
      "\n",
      "Since the outbreak, Chinese officials have received at least 274 complaints about price-gouging and hoarding , according to Reuters. In Italy, which has been hit particularly hard by the coronavirus outbreak compared with other European countries, authorities have opened an investigation into high prices for surgical masks, according to Reuters.\n",
      "\n",
      "\n",
      "\n",
      "This issue isn't a first for Amazon. Following Hurricane Irma in 2017, Amazon faced criticism after customers reported wildly inflated prices , at which point it said it would begin taking action against vendors.\n",
      "\n",
      "\n",
      "\n",
      "Amazon could not immediately be reached for comment.\n"
     ]
    }
   ],
   "source": [
    "with open(args.text_src, 'r') as f:\n",
    "    for l in f:\n",
    "        print(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = load_text(args, args.text_src, args.text_tgt, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "> /notebooks/PreSumm/src/models/data_loader.py(333)load_text()\n",
      "-> src, mask_src, segments_ids, clss, mask_cls = _process_src(x)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|â–‹         | 1/15 [00:02<00:29,  2.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<models.data_loader.Batch object at 0x7fa90409f780>\n",
      "> /notebooks/PreSumm/src/models/data_loader.py(333)load_text()\n",
      "-> src, mask_src, segments_ids, clss, mask_cls = _process_src(x)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(334)load_text()\n",
      "-> segs = torch.tensor(segments_ids)[None, :].to(device)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(335)load_text()\n",
      "-> batch = Batch()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(336)load_text()\n",
      "-> batch.src  = src\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(337)load_text()\n",
      "-> batch.tgt  = None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(338)load_text()\n",
      "-> batch.mask_src  = mask_src\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(339)load_text()\n",
      "-> batch.mask_tgt  = None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(340)load_text()\n",
      "-> batch.segs  = segs\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(341)load_text()\n",
      "-> batch.src_str  =  [[sent.replace('[SEP]','').strip() for sent in x.split('[CLS]')]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(342)load_text()\n",
      "-> batch.tgt_str  = ['']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(343)load_text()\n",
      "-> batch.clss  = clss\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(344)load_text()\n",
      "-> batch.mask_cls  = mask_cls\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(346)load_text()\n",
      "-> batch.batch_size=1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /notebooks/PreSumm/src/models/data_loader.py(347)load_text()\n",
      "-> yield batch\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<models.data_loader.Batch object at 0x7fa8ab92f860>\n"
     ]
    }
   ],
   "source": [
    "for item in test_iter:\n",
    "    print(item)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
